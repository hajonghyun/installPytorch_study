{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DpkY_pppzIu4EMe4zllsWS3MWpNLvTrm",
      "authorship_tag": "ABX9TyOQQN+A3+OTQbHaj3BDWweg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hajonghyun/installPytorch_study/blob/main/5_torch_multiclass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kjacM1rR5uHY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 드라이브와 연동 (코랩 새로 켤때마다 지워지기 때문에)"
      ],
      "metadata": {
        "id": "puRo1Ek47OEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07i_l6lP6H1e",
        "outputId": "65867004-3d5d-4edd-be64-5157f7e13bb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 GPU 사용"
      ],
      "metadata": {
        "id": "ApPwqcpb_WWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVESgArE62dw",
        "outputId": "c9325a40-ecfe-4b1c-94eb-a8209b254c20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train_DS 와 test_DS 구경"
      ],
      "metadata": {
        "id": "VsqT5qGiAxeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "train_DS = datasets.MNIST(root = '/content/drive/MyDrive/ROKAF/인스톨 파이토치/data', train=True, download=True, transform=transform)\n",
        "test_DS = datasets.MNIST(root = '/content/drive/MyDrive/ROKAF/인스톨 파이토치/data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "BVYRDPcB_5YY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch: `transforms.ToTensor()`의 핵심 역할\n",
        "\n",
        "`transforms.ToTensor()`는 이미지 데이터(Raw Data)를 파이토치 모델이 학습할 수 있는 **'표준 규격'**으로 변환하는 **필수 전처리 도구**입니다.\n",
        "\n",
        "## 1. 3가지 핵심 기능\n",
        "이 함수는 한 번에 다음 세 가지 작업을 수행합니다.\n",
        "\n",
        "1.  **자료형 변환 (Type Conversion)**\n",
        "    * `PIL Image` 또는 `numpy.ndarray` (정수형 `uint8`) $\\rightarrow$ **`FloatTensor` (실수형 `float32`)**\n",
        "    * **이유:** 신경망의 가중치 업데이트(미분)를 위해서는 정밀한 실수 연산이 필수입니다.\n",
        "\n",
        "2.  **스케일링 (Scaling)**\n",
        "    * **0 ~ 255** 범위의 픽셀 값 $\\rightarrow$ **0.0 ~ 1.0** 범위로 정규화\n",
        "    * **이유:** 큰 숫자는 기울기 폭주(Gradient Exploding)를 유발합니다. 0~1 사이의 작은 값에서 학습이 가장 안정적입니다.\n",
        "\n",
        "3.  **차원 변경 (Dimension Swap) ★ 중요**\n",
        "    * **(H, W, C)** $\\rightarrow$ **(C, H, W)**\n",
        "    * `높이, 너비, 채널` 순서의 데이터를 파이토치 표준인 `채널, 높이, 너비` 순서로 바꿉니다.\n",
        "    * **이유:** 파이토치 내부 연산(Conv2d 등)은 채널(C)이 가장 앞에 오는 것을 전제로 구현되어 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Code: Before & After 비교\n",
        "가상의 픽셀 데이터(빨간점 하나)를 통해 변환 과정을 확인합니다.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# [Before] 원본 데이터 (Numpy)\n",
        "# 구조: (높이 H=1, 너비 W=1, 채널 C=3), 값 범위: 0~255\n",
        "raw_data = np.array([[[255, 0, 0]]], dtype='uint8')\n",
        "\n",
        "print(f\"원본 모양: {raw_data.shape}\")\n",
        "print(f\"원본 값:\\n{raw_data}\")\n",
        "\n",
        "# --- 변환 수행 ---\n",
        "transform = transforms.ToTensor()\n",
        "tensor_data = transform(raw_data)\n",
        "# -----------------\n",
        "\n",
        "# [After] 변환 데이터 (Tensor)\n",
        "# 구조: (채널 C=3, 높이 H=1, 너비 W=1), 값 범위: 0.0~1.0\n",
        "print(f\"변환 모양: {tensor_data.shape}\")\n",
        "print(f\"변환 값:\\n{tensor_data}\")\n",
        "```\n",
        "\n",
        "### 3. 실행 결과 (Output)\n",
        "\n",
        "```text\n",
        "원본 모양: (1, 1, 3)\n",
        "원본 값:\n",
        "[[[255   0   0]]]\n",
        "\n",
        "------------------------------\n",
        "\n",
        "변환 모양: torch.Size([3, 1, 1])  <-- 채널(3)이 맨 앞으로 이동 (C, H, W)\n",
        "변환 값:\n",
        "tensor([[[1.],      <-- 255가 1.0으로 스케일링 됨 (R)\n",
        "         [0.],      <-- (G)\n",
        "         [0.]]])    <-- (B)\n",
        "```\n",
        "\n",
        "## 요약\n",
        "`transforms.ToTensor()`를 사용하지 않으면 모델은 데이터를 **입력받을 수 없습니다(Shape Mismatch)**. 모델이 소화하기 좋게 **\"자르고(차원변경), 으깨서(스케일링), 부드럽게(실수변환)\"** 만들어주는 과정입니다."
      ],
      "metadata": {
        "id": "NxXW-RuUOxo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_DS)\n",
        "print(test_DS)\n",
        "print(len(train_DS))\n",
        "print(len(test_DS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGpYQUxLBaR7",
        "outputId": "3b9210f3-df04-461b-cacd-7d6023738af0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: /content/drive/MyDrive/ROKAF/인스톨 파이토치/data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: /content/drive/MyDrive/ROKAF/인스톨 파이토치/data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS.classes # . 뒤에 탭 하면 이것저것 뜬다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmRygwV1RS8P",
        "outputId": "a3b6c56e-8993-4f94-ab0f-eff308a912bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS.class_to_idx # 클래스에 대한 label을 볼 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZW1StfNRft6",
        "outputId": "779358ed-c93b-4c8d-99ae-c8a3049da705"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0 - zero': 0,\n",
              " '1 - one': 1,\n",
              " '2 - two': 2,\n",
              " '3 - three': 3,\n",
              " '4 - four': 4,\n",
              " '5 - five': 5,\n",
              " '6 - six': 6,\n",
              " '7 - seven': 7,\n",
              " '8 - eight': 8,\n",
              " '9 - nine': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS.data.shape # 28X28 짜리 이미지가 60000개 들어있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsPuJ7t2Twfv",
        "outputId": "ca081caa-e583-4bb0-d8d2-611cca540066"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HZSWD4FOcd5",
        "outputId": "2d0f93e3-84df-4875-831e-8e0f2045a5d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYx5Ll57UUm9",
        "outputId": "b180f982-5a8a-4aa6-a554-2c136c747063"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
              "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
              "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
              "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
              "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
              "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
              "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
              "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
              "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
              "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
              "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
              "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [PyTorch] 개념 확실히 잡기: `.data[0]` vs `[0]`의 차이\n",
        "\n",
        "데이터셋에서 데이터를 꺼내는 두 가지 방식의 차이는 **\"요리 전이냐, 요리 후냐\"**의 차이입니다.\n",
        "\n",
        "## 1. 핵심 비유 (Analogy)\n",
        "| 코드 | 비유 | 상태 | 설명 |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **`train_DS.data[0]`** | **냉장고 속 생고기** | **Raw Data** | 창고에 쌓여있는 **원본 그대로**의 상태. (먹을 수 없음/학습 불가) |\n",
        "| **`train_DS[0]`** | **잘 구워진 스테이크** | **Processed** | 주문(인덱싱)이 들어오자마자 **손질(Transform)**해서 내온 상태. (먹을 수 있음/학습 가능) |\n",
        "\n",
        "## 2. 기술적 차이점 비교\n",
        "\n",
        "| 구분 | `dataset.data[index]` | `dataset[index]` |\n",
        "| :--- | :--- | :--- |\n",
        "| **호출 대상** | 내부 변수(속성) 직접 접근 | **`__getitem__` 메서드** 실행 |\n",
        "| **Transform 적용** | **X** (적용 안 됨) | **O** (`ToTensor` 적용 됨) |\n",
        "| **값의 범위** | **0 ~ 255** (정수) | **0.0 ~ 1.0** (실수) |\n",
        "| **데이터 타입** | `torch.uint8` (1 Byte) | `torch.float32` (4 Bytes) |\n",
        "\n",
        "## 3. \"왜 미리 변환해서 저장하지 않는가?\" (Why?)\n",
        "**메모리 효율성(Memory Efficiency)** 때문입니다.\n",
        "\n",
        "* **`uint8` (원본)**: 픽셀당 1바이트만 차지.\n",
        "* **`float32` (변환 후)**: 픽셀당 4바이트 차지.\n",
        "\n",
        "만약 모든 데이터를 미리 `float32`로 변환해서 메모리에 올려두면, **RAM 사용량이 4배로 폭증**하여 컴퓨터가 멈출 수 있습니다. 그래서 파이토치는 **\"저장은 압축해서(Raw), 사용은 그때그때 변환해서(On-the-fly)\"** 방식을 사용합니다.\n",
        "\n",
        "## 4. 내부 동작 코드 (Mental Model)\n",
        "우리가 `train_DS[0]`이라고 코드를 칠 때, 내부에서는 아래 함수가 실행됩니다.\n",
        "\n",
        "```python\n",
        "def __getitem__(self, index):\n",
        "    # 1. 창고(self.data)에서 원본(0~255)을 꺼낸다\n",
        "    img = self.data[index]\n",
        "    \n",
        "    # 2. 이 순간에 Transform이 개입한다! (여기가 핵심)\n",
        "    #    (0~255 -> 0.0~1.0으로 변환 및 차원 변경)\n",
        "    if self.transform is not None:\n",
        "        img = self.transform(img)\n",
        "        \n",
        "    # 3. 변환된 결과(Tensor)를 반환한다\n",
        "    return img, target\n",
        "```\n",
        "\n",
        "++\n",
        "\n",
        "train_DS[0]은 이미지 하나만 덜렁 주는 게 아니라, (이미지, 정답 라벨) 이렇게 두 개가 묶인 **튜플(Tuple)**입니다"
      ],
      "metadata": {
        "id": "ZtHfl8AORpue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_DS.data[0],cmap='gray')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "9dLEEsShUca1",
        "outputId": "28abd6a1-569a-49e5-a621-c5b8875f9cf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7e7c3ddab560>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_DS.targets)\n",
        "print(train_DS.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXRkcqRoVR9a",
        "outputId": "0e121bc1-f9ee-4fd4-f133-28e35e63603b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 0, 4,  ..., 5, 6, 8])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_DS.data[1],cmap='gray')\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "sIfVnVidVfG8",
        "outputId": "58177022-e4ed-4eff-e15f-e15662d5bd3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7e7c3db4eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAGdCAYAAADtxiFiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALCVJREFUeJzt3X1wVGWa/vGrE0kTJN2ZBpJO1oQN+ILIm4MQUiqipEiCi6KpLUFGwaJgZRJLyIhWthCQsSo1jKuuFMK+KOgO8a12gJF14maChHVNGMVlGRw3RbKZSijSYYyTBOKQRHJ+f/Cj11aQnE53Og/n+6l6qsjp8/S50zZc3s853cdlWZYlAABglLhYFwAAAOwjwAEAMBABDgCAgQhwAAAMRIADAGAgAhwAAAMR4AAAGIgABwDAQFfFuoBv6+vr08mTJ5WUlCSXyxXrcgAANlmWpdOnTys9PV1xcdHrE8+ePauenp4BP09CQoKGDx8egYoG15AL8JMnTyojIyPWZQAABqi5uVnXXHNNVJ777NmzysrKUiAQGPBz+f1+NTY2GhfiQy7Ak5KSYl0CACACovnveU9PjwKBgJqamuTxeMJ+ns7OTmVmZqqnp4cAv2Dr1q36+c9/rkAgoKlTp2rLli2aOXPmZeexbA4AV4bB+Pfc4/EMKMBNFpWTE2+99ZZKSkq0YcMGffrpp5o6dary8vJ06tSpaBwOAOBQlmUNeNhRVlamGTNmKCkpSSkpKVq4cKHq6upC9pkzZ45cLlfIePTRR0P2aWpq0t13360RI0YoJSVFa9eu1ddff22rlqgE+PPPP68VK1bokUce0cSJE7V9+3aNGDFCr776ajQOBwBwqMEO8OrqahUVFam2tlaVlZXq7e3VvHnz1NXVFbLfihUr1NLSEhybN28OPnbu3Dndfffd6unp0UcffaTXXntNO3fu1Pr1623/8hHV3d1txcfHW7t37w7Z/vDDD1v33HPPd/Y/e/as1dHRERzNzc2WJAaDwWAYPjo6OiIdMUEdHR2WJKutrc3q7e0Ne7S1tQ2o1lOnTlmSrOrq6uC2O+64w3r88ccvOee9996z4uLirEAgENy2bds2y+PxWN3d3f0+dsQ78C+++ELnzp1TampqyPbU1NSLXi1YVlYmr9cbHFyBDgAYbJ2dnSGju7u7X/M6OjokST6fL2T7rl27NHr0aE2aNEmlpaX66quvgo/V1NRo8uTJITmZl5enzs5OffbZZ/2uOeZf5FJaWqqOjo7gaG5ujnVJAABDWBFaQs/IyAhpJsvKyi577L6+Pq1evVq33nqrJk2aFNz+4IMP6he/+IU++OADlZaW6l/+5V/0ox/9KPh4IBC4aJN74bH+ivhV6KNHj1Z8fLxaW1tDtre2tsrv939nf7fbLbfbHekyAAAOYIVxHvvb86Xzn1n/5tXs/cmloqIiHTt2TB9++GHI9pUrVwb/PHnyZKWlpWnu3LlqaGjQ+PHjw6712yLegSckJGj69OmqqqoKbuvr61NVVZVycnIifTgAAAbswsfRLozLBXhxcbH27dunDz744LJfVpOdnS1Jqq+vl3T+i2Mu1uReeKy/orKEXlJSon/6p3/Sa6+9ps8//1yrVq1SV1eXHnnkkWgcDgDgUJFaQrdzvOLiYu3evVv79+9XVlbWZeccOXJEkpSWliZJysnJ0e9+97uQj1ZXVlbK4/Fo4sSJtoqJii1btliZmZlWQkKCNXPmTKu2trZf8y5cWchgMBgMs8dgXIXe2tpq/fnPfw57tLa22qp11apVltfrtQ4cOGC1tLQEx1dffWVZlmXV19dbmzZtsj755BOrsbHR2rt3rzVu3Dhr9uzZwef4+uuvrUmTJlnz5s2zjhw5YlVUVFhjxoyxSktLbb0GUQvwcBHgDAaDcWWMKzHAL/W77tixw7Isy2pqarJmz55t+Xw+y+12W9dee621du3a7zz/H/7wB6ugoMBKTEy0Ro8ebf3kJz+xent7bb0Grv9f0JDR2dkpr9cb6zIAAAPU0dERta85vZAVgUBgwN+F7vf7o1prtAy5m5kAANBfVoSuQjdRzD8HDgAA7KMDBwAYy8kdOAEOADAWAQ4AgIGcHOCcAwcAwEB04AAAYzm5AyfAAQDGcnKAs4QOAICB6MABAMZycgdOgAMAjOXkAGcJHQAAA9GBAwCM5eQOnAAHABjN5BAeCJbQAQAwEB04AMBYLKEDAGAgAhwAAAM5OcA5Bw4AgIHowAEAxnJyB06AAwCM5eQAZwkdAAAD0YEDAIzl5A6cAAcAGMvJAc4SOgAABqIDBwAYy8kdOAEOADCWkwOcJXQAAAxEBw4AMJaTO3ACHABgLAIcAAADOTnAOQcOAICB6MABAMZycgdOgAMAjOXkAGcJHQAAA9GBAwCM5eQOnAAHABjLyQHOEjoAAAaiAwcMMX36dNtziouLwzrWww8/bHvO66+/bnvOli1bbM/59NNPbc/BlcvJHTgBDgAwmskhPBAsoQMAYCA6cACAsVhCBwDAQAQ4AAAGcnKAcw4cAAAD0YEDAIzl5A6cAAcAGMvJAc4SOgAABqIDBwAYy8kdOAEOADCWkwOcJXQAAAxEBw7EwLRp02zPqaystD3H4/HYniOF15U89NBDtufcc889tueMGjXK9hxcuZzcgRPgAABjOTnAWUIHAMBAEQ/wjRs3yuVyhYwJEyZE+jAAAAQ78IEMU0VlCf2mm27Sb37zm/87yFWs1AMAIs/JS+hRSdarrrpKfr8/Gk8NAECQkwM8KufAjx8/rvT0dI0bN05LlixRU1PTJfft7u5WZ2dnyAAAAN8v4gGenZ2tnTt3qqKiQtu2bVNjY6Nuv/12nT59+qL7l5WVyev1BkdGRkakSwIAXKGcfA484gFeUFCgv/7rv9aUKVOUl5en9957T+3t7Xr77bcvun9paak6OjqCo7m5OdIlAQCuUE4O8KhfXZacnKzrr79e9fX1F33c7XbL7XZHuwwAAK4oUf8c+JkzZ9TQ0KC0tLRoHwoA4DCD3YGXlZVpxowZSkpKUkpKihYuXKi6urqQfc6ePauioiKNGjVKI0eOVGFhoVpbW0P2aWpq0t13360RI0YoJSVFa9eu1ddff22rlogH+BNPPKHq6mr94Q9/0EcffaT77rtP8fHxWrx4caQPBQBwuMEO8OrqahUVFam2tlaVlZXq7e3VvHnz1NXVFdxnzZo1evfdd/XOO++ourpaJ0+e1P333x98/Ny5c7r77rvV09Ojjz76SK+99pp27typ9evX26ol4kvoJ06c0OLFi9XW1qYxY8botttuU21trcaMGRPpQwEAMKgqKipCft65c6dSUlJ0+PBhzZ49Wx0dHXrllVdUXl6uu+66S5K0Y8cO3XjjjaqtrdWsWbP07//+7/r973+v3/zmN0pNTdW0adP005/+VE899ZQ2btyohISEftUS8QB/8803I/2UwJA2c+ZM23P+9V//1fYcr9dre064F+hc6lMj36enp8f2nHBuTDJr1izbcz799FPbc6TwficMrkh9DvzbH2Hu7/VZHR0dkiSfzydJOnz4sHp7e5WbmxvcZ8KECcrMzFRNTY1mzZqlmpoaTZ48WampqcF98vLytGrVKn322We6+eab+1U734UOADBaJJbPMzIyQj7SXFZWdtnj9vX1afXq1br11ls1adIkSVIgEFBCQoKSk5ND9k1NTVUgEAju883wvvD4hcf6i+84BQA4XnNzc8jtd/vTfRcVFenYsWP68MMPo1naJRHgAABjRWoJ3ePxhAT45RQXF2vfvn06ePCgrrnmmuB2v9+vnp4etbe3h3Thra2twa8Y9/v9+u1vfxvyfBeuUrfzNeQsoQMAjDXYV6FblqXi4mLt3r1b+/fvV1ZWVsjj06dP17Bhw1RVVRXcVldXp6amJuXk5EiScnJy9Lvf/U6nTp0K7lNZWSmPx6OJEyf2uxY6cACAsQb7ZiZFRUUqLy/X3r17lZSUFDxn7fV6lZiYKK/Xq+XLl6ukpEQ+n08ej0ePPfaYcnJyghdgzps3TxMnTtRDDz2kzZs3KxAIaN26dSoqKrL1xWYEOAAA/bRt2zZJ0pw5c0K279ixQ8uWLZMkvfDCC4qLi1NhYaG6u7uVl5enl19+ObhvfHy89u3bp1WrViknJ0dXX321li5dqk2bNtmqhQAHABhrsDvw/uw/fPhwbd26VVu3br3kPmPHjtV7771n69jfRoADAIzF/cABAIBR6MABAMZycgdOgAMAjOXkAGcJHQAAA9GB44o0YsSIsOb98Ic/tD3nF7/4he05aWlptucMpuPHj9ues3nzZttzwrn50X/+53/anrNu3TrbcyT16/uwEVtO7sAJcACAsZwc4CyhAwBgIDpwAICxnNyBE+AAAGMR4AAAGMjJAc45cAAADEQHDgAwlpM7cAIcAGAsJwc4S+gAABiIDhwAYCwnd+AEOADAWE4OcJbQAQAwEB04AMBYTu7ACXBckf7hH/4hrHmLFy+OcCVmCueubCNHjrQ9p7q62vacOXPm2J4zZcoU23NgDpNDeCBYQgcAwEB04AAAY7GEDgCAgQhwAAAM5OQA5xw4AAAGogMHABjLyR04AQ4AMJaTA5wldAAADEQHDgAwlpM7cAIcAGAsJwc4S+gAABiIDhwAYCwnd+AEOIa86dOn255z9913h3Usl8sV1jy7wrmJx7vvvmt7znPPPWd7jiSdPHnS9pz/+q//sj3nT3/6k+05d911l+05g/XfFYPPyQHOEjoAAAaiAwcAGMvJHTgBDgAwFgEOAICBnBzgnAMHAMBAdOAAAGM5uQMnwAEAxnJygLOEDgCAgejAAQDGcnIHToADAIzl5ABnCR0AAAPRgQMAjOXkDpwAx6CaNm2a7TmVlZW253g8HttzpPD+Mv/617+2PWfx4sW259xxxx2256xbt872HEn653/+Z9tz/vjHP9qe89///d+25/T19dmeE+7NbX74wx/anvPpp5+GdSyEx8kBzhI6AAAGogMHABjN5C56IGx34AcPHtSCBQuUnp4ul8ulPXv2hDxuWZbWr1+vtLQ0JSYmKjc3V8ePH49UvQAABF1YQh/IMJXtAO/q6tLUqVO1devWiz6+efNmvfTSS9q+fbsOHTqkq6++Wnl5eTp79uyAiwUA4JucHOC2l9ALCgpUUFBw0ccsy9KLL76odevW6d5775Ukvf7660pNTdWePXu0aNGigVULAAAkRfgitsbGRgUCAeXm5ga3eb1eZWdnq6am5qJzuru71dnZGTIAAOgPJ3fgEQ3wQCAgSUpNTQ3ZnpqaGnzs28rKyuT1eoMjIyMjkiUBAK5gBHgMlZaWqqOjIziam5tjXRIAAENeRD9G5vf7JUmtra1KS0sLbm9tbb3kF3i43W653e5IlgEAcAi+yCVCsrKy5Pf7VVVVFdzW2dmpQ4cOKScnJ5KHAgDA0UvotjvwM2fOqL6+PvhzY2Ojjhw5Ip/Pp8zMTK1evVrPPvusrrvuOmVlZenpp59Wenq6Fi5cGMm6AQBwNNsB/sknn+jOO+8M/lxSUiJJWrp0qXbu3Kknn3xSXV1dWrlypdrb23XbbbepoqJCw4cPj1zVAADI2UvotgN8zpw53/sLu1wubdq0SZs2bRpQYRj6rr/+ettz1q5da3uO1+u1PeeLL76wPUeSWlpabM957bXXbM85c+aM7Tn/9m//NihzrkSJiYlhzfvJT35ie86SJUvCOhbCQ4ADAGAgJwd4zD9GBgAA7KMDBwAYiw4cAAADxeJjZJe7K+eyZcvkcrlCRn5+fsg+X375pZYsWSKPx6Pk5GQtX77c9rUxBDgAADZc7q6ckpSfn6+WlpbgeOONN0IeX7JkiT777DNVVlZq3759OnjwoFauXGmrDpbQAQDGisUS+vfdlfMCt9sd/HbSb/v8889VUVGhjz/+WLfccoskacuWLZo/f76ee+45paen96sOOnAAgLEitYT+7btidnd3D6iuAwcOKCUlRTfccINWrVqltra24GM1NTVKTk4Ohrck5ebmKi4uTocOHer3MQhwAIDjZWRkhNwZs6ysLOznys/P1+uvv66qqir97Gc/U3V1tQoKCnTu3DlJ5+/cmZKSEjLnqquuks/nu+SdOy+GJXQAgLEitYTe3Nwsj8cT3D6Qm2wtWrQo+OfJkydrypQpGj9+vA4cOKC5c+eG/bzfRgcOADBWpJbQPR5PyIjkXTLHjRun0aNHB+8j4vf7derUqZB9vv76a3355ZeXPG9+MQQ4AABRdOLECbW1tQVvs52Tk6P29nYdPnw4uM/+/fvV19en7Ozsfj8vS+gAAGPF4ir077srp8/n0zPPPKPCwkL5/X41NDToySef1LXXXqu8vDxJ0o033qj8/HytWLFC27dvV29vr4qLi7Vo0aJ+X4Eu0YEDAAwWiy9y+eSTT3TzzTfr5ptvlnT+rpw333yz1q9fr/j4eB09elT33HOPrr/+ei1fvlzTp0/Xf/zHf4Qsy+/atUsTJkzQ3LlzNX/+fN122236x3/8R1t10IEj7HM9zz33nO058+fPtz3n9OnTtuc8/PDDtudI5/9i2hXuna4w9GVmZsa6BPTDYH8d6uXuyvn+++9f9jl8Pp/Ky8sHVAcdOAAABqIDBwAYy8k3MyHAAQDGcnKAs4QOAICB6MABAMZycgdOgAMAjOXkAGcJHQAAA9GBAwCM5eQOnAAHABjLyQHOEjoAAAaiAwcAGMvJHTgBDgAwFgEOR7twRx27wrkxSTjuvfde23Oqq6ujUAmAocbJAc45cAAADEQHDgAwlpM7cAIcAGAsJwc4S+gAABiIDhwAYCwnd+AEOADAWE4OcJbQAQAwEB04AMBYTu7ACXAAgLGcHOAsoQMAYCA6cACAsZzcgRPgAABjEeBwtOeffz6seS6Xy/accG4ywo1J8E1xcfbP/PX19UWhEgwVJofwQHAOHAAAA9GBAwCMxRI6AAAGcnKAs4QOAICB6MABAMZycgdOgAMAjOXkAGcJHQAAA9GBAwCM5eQOnAAHABjLyQHOEjoAAAaiAwcAGMvJHTgBDgAwFgGOK8Zf/dVf2Z4zbdq0sI4Vzhv/V7/6VVjHAi4I58Yk4f4jfeTIkbDmYfA4OcA5Bw4AgIHowAEAxqIDt+HgwYNasGCB0tPT5XK5tGfPnpDHly1bJpfLFTLy8/MjVS8AAEEXAnwgw1S2A7yrq0tTp07V1q1bL7lPfn6+WlpaguONN94YUJEAACCU7SX0goICFRQUfO8+brdbfr8/7KIAAOgPltAj7MCBA0pJSdENN9ygVatWqa2t7ZL7dnd3q7OzM2QAANAfLKFHUH5+vl5//XVVVVXpZz/7maqrq1VQUKBz585ddP+ysjJ5vd7gyMjIiHRJAABccSJ+FfqiRYuCf548ebKmTJmi8ePH68CBA5o7d+539i8tLVVJSUnw587OTkIcANAvLKFH0bhx4zR69GjV19df9HG32y2PxxMyAADoD5bQo+jEiRNqa2tTWlpatA8FAIBj2F5CP3PmTEg33djYqCNHjsjn88nn8+mZZ55RYWGh/H6/Ghoa9OSTT+raa69VXl5eRAsHAMDJS+i2A/yTTz7RnXfeGfz5wvnrpUuXatu2bTp69Khee+01tbe3Kz09XfPmzdNPf/pTud3uyFUNAIAIcFvmzJnzvb/w+++/P6CCMDCJiYm25yQkJIR1rFOnTtme89Zbb4V1LAx94fxP+saNGyNfyEXs378/rHmlpaURrgTRYHIIDwQ3MwEAwEDczAQAYCyW0AEAMJCTA5wldAAADEQHDgAwlpM7cAIcAGAsJwc4S+gAABiIDhwAYCwnd+AEOADAWE4OcJbQAQCw4eDBg1qwYIHS09Plcrm0Z8+ekMcty9L69euVlpamxMRE5ebm6vjx4yH7fPnll1qyZIk8Ho+Sk5O1fPlynTlzxlYdBDgAwFixuJ1oV1eXpk6dqq1bt1708c2bN+ull17S9u3bdejQIV199dXKy8vT2bNng/ssWbJEn332mSorK7Vv3z4dPHhQK1eutFUHS+gAAGPFYgm9oKBABQUFl3y+F198UevWrdO9994rSXr99deVmpqqPXv2aNGiRfr8889VUVGhjz/+WLfccoskacuWLZo/f76ee+45paen96sOOnAAgLEi1YF3dnaGjO7u7rDqaWxsVCAQUG5ubnCb1+tVdna2ampqJEk1NTVKTk4Ohrck5ebmKi4uTocOHer3sejAEbZw3uAtLS1RqASRFs6dxdatW2d7ztq1a23POXHihO05f/d3f2d7jiTb5yRhroyMjJCfN2zYENbd8gKBgCQpNTU1ZHtqamrwsUAgoJSUlJDHr7rqKvl8vuA+/UGAAwCMFakl9ObmZnk8nuD2cP4ndrCxhA4AMFakltA9Hk/ICDfA/X6/JKm1tTVke2tra/Axv9+vU6dOhTz+9ddf68svvwzu0x8EOAAAEZKVlSW/36+qqqrgts7OTh06dEg5OTmSpJycHLW3t+vw4cPBffbv36++vj5lZ2f3+1gsoQMAjBWLq9DPnDmj+vr64M+NjY06cuSIfD6fMjMztXr1aj377LO67rrrlJWVpaefflrp6elauHChJOnGG29Ufn6+VqxYoe3bt6u3t1fFxcVatGhRv69AlwhwAIDBYhHgn3zyie68887gzyUlJZKkpUuXaufOnXryySfV1dWllStXqr29XbfddpsqKio0fPjw4Jxdu3apuLhYc+fOVVxcnAoLC/XSSy/ZqoMABwDAhjlz5nxv8LtcLm3atEmbNm265D4+n0/l5eUDqoMABwAYy8nfhU6AAwCM5eQA5yp0AAAMRAcOADCWkztwAhwAYCwCHAAAQ5kcwgNBgCNsv/rVr2JdAi5j2rRpYc0L5yYjDzzwgO05e/futT2nsLDQ9hzgSkSAAwCMxRI6AAAGcnKA8zEyAAAMRAcOADCWkztwAhwAYCwnBzhL6AAAGIgOHABgLCd34AQ4AMBYTg5wltABADAQHTgAwFhO7sAJcACAsQhwAAAMRIDjiuFyuQZljiQtXLjQ9pzHH388rGNBWrNmje05Tz/9dFjH8nq9tufs2rXL9pyHH37Y9hwA5xHgAABj0YEDAGAgJwc4HyMDAMBAdOAAAGM5uQMnwAEAxnJygLOEDgCAgejAAQDGcnIHToADAIzl5ABnCR0AAAPRgQMAjOXkDpwABwAYiwAHAMBABDiuGOG8GcN9A/v9fttzXnrpJdtzXn31Vdtz2trabM+RpFmzZtme89BDD9meM3XqVNtzrrnmGttzmpqabM+RpPfff9/2nJdffjmsYwEIDwEOADCayV30QBDgAABjOXkJ3dbHyMrKyjRjxgwlJSUpJSVFCxcuVF1dXcg+Z8+eVVFRkUaNGqWRI0eqsLBQra2tES0aAACnsxXg1dXVKioqUm1trSorK9Xb26t58+apq6sruM+aNWv07rvv6p133lF1dbVOnjyp+++/P+KFAwBwoQMfyDCVrSX0ioqKkJ937typlJQUHT58WLNnz1ZHR4deeeUVlZeX66677pIk7dixQzfeeKNqa2vDukAIAIBLYQk9TB0dHZIkn88nSTp8+LB6e3uVm5sb3GfChAnKzMxUTU3NRZ+ju7tbnZ2dIQMAAHy/sAO8r69Pq1ev1q233qpJkyZJkgKBgBISEpScnByyb2pqqgKBwEWfp6ysTF6vNzgyMjLCLQkA4DBOXkIPO8CLiop07NgxvfnmmwMqoLS0VB0dHcHR3Nw8oOcDADiHkwM8rI+RFRcXa9++fTp48GDIl0v4/X719PSovb09pAtvbW295Jd+uN1uud3ucMoAAMCxbHXglmWpuLhYu3fv1v79+5WVlRXy+PTp0zVs2DBVVVUFt9XV1ampqUk5OTmRqRgAgP+PDryfioqKVF5err179yopKSl4Xtvr9SoxMVFer1fLly9XSUmJfD6fPB6PHnvsMeXk5HAFOgAg4px8FbqtAN+2bZskac6cOSHbd+zYoWXLlkmSXnjhBcXFxamwsFDd3d3Ky8vjO5IBAFFBgPdTf37R4cOHa+vWrdq6dWvYRcEM8fHxtuf8+Mc/tj2nsLDQ9pxwP4543XXXhTVvMHz00Ue253zwwQdhHWv9+vVhzQMwePgudACAsejAAQAwkJMDfEDfxAYAAGKDDhwAYCwnd+AEOADAWE4OcJbQAQAwEB04AMBYTu7ACXAAgLGcHOAsoQMAYCA6cACAsZzcgRPgAABjEeAAABjIyQHOOXAAAAxEB36FqampsT3n448/DutYM2bMCGueXX6/3/ac1NTUKFRycW1tbbbnvPnmm7bnPP7447bnAE5gchc9EAQ4AMBYLKEDAACjEOAAAGNd6MAHMuzYuHGjXC5XyJgwYULw8bNnz6qoqEijRo3SyJEjVVhYqNbW1kj/2pIIcACAwQY7wCXppptuUktLS3B8+OGHwcfWrFmjd999V++8846qq6t18uRJ3X///ZH8lYM4Bw4AgA1XXXXVRS+u7ejo0CuvvKLy8nLdddddkqQdO3boxhtvVG1trWbNmhXROujAAQDGilQH3tnZGTK6u7sveczjx48rPT1d48aN05IlS9TU1CRJOnz4sHp7e5Wbmxvcd8KECcrMzAzrE0KXQ4ADAIwVqQDPyMiQ1+sNjrKysoseLzs7Wzt37lRFRYW2bdumxsZG3X777Tp9+rQCgYASEhKUnJwcMic1NVWBQCDivztL6AAAx2tubpbH4wn+7Ha7L7pfQUFB8M9TpkxRdna2xo4dq7fffluJiYlRr/Ob6MABAMaKVAfu8XhCxqUC/NuSk5N1/fXXq76+Xn6/Xz09PWpvbw/Zp7W1NawvpLocAhwAYKxYXIX+TWfOnFFDQ4PS0tI0ffp0DRs2TFVVVcHH6+rq1NTUpJycnIH+qt/BEjoAwFiD/U1sTzzxhBYsWKCxY8fq5MmT2rBhg+Lj47V48WJ5vV4tX75cJSUl8vl88ng8euyxx5STkxPxK9AlAhwAgH47ceKEFi9erLa2No0ZM0a33XabamtrNWbMGEnSCy+8oLi4OBUWFqq7u1t5eXl6+eWXo1KLyxpiXwTb2dkpr9cb6zIcJS0tLax5f/M3f2N7zrp162zPcblctueE+7b++7//e9tztm3bZntOfX297TmAaTo6OkIuDIukC1kxceJExcfHh/08586d0+9///uo1hotdOAAAGNxMxMAAGAUOnAAgLGc3IET4AAAYzk5wFlCBwDAQHTgAABjObkDJ8ABAMZycoCzhA4AgIHowAEAxnJyB06AAwCMRYADAGAgJwc458ABADAQNzMBAETFYNzMZNy4cYqLC78X7evr0//+7/9yMxMAAAYTS+gAAMAodOAAAGM5uQMnwAEAxnJygLOEDgCAgejAAQDGcnIHToADAIzl5ABnCR0AAAPRgQMAjOXkDpwABwAYiwAHAMBATg5wzoEDAGAgOnAAgLGc3IET4AAAYzk5wFlCBwDAQLYCvKysTDNmzFBSUpJSUlK0cOFC1dXVhewzZ84cuVyukPHoo49GtGgAAKT/68AHMkxlK8Crq6tVVFSk2tpaVVZWqre3V/PmzVNXV1fIfitWrFBLS0twbN68OaJFAwAgOTvAbZ0Dr6ioCPl5586dSklJ0eHDhzV79uzg9hEjRsjv90emQgAA8B0DOgfe0dEhSfL5fCHbd+3apdGjR2vSpEkqLS3VV199dcnn6O7uVmdnZ8gAAKA/6MDD0NfXp9WrV+vWW2/VpEmTgtsffPBBjR07Vunp6Tp69Kieeuop1dXV6Ze//OVFn6esrEzPPPNMuGUAABzMyVehu6wwq1+1apV+/etf68MPP9Q111xzyf3279+vuXPnqr6+XuPHj//O493d3eru7g7+3NnZqYyMjHBKAgAMIR0dHfJ4PFF57s7OTnm9Xo0ePVpxceEvJvf19emLL76Iaq3RElYHXlxcrH379ungwYPfG96SlJ2dLUmXDHC32y232x1OGQAAh3NyB24rwC3L0mOPPabdu3frwIEDysrKuuycI0eOSJLS0tLCKhAAgEshwPupqKhI5eXl2rt3r5KSkhQIBCRJXq9XiYmJamhoUHl5uebPn69Ro0bp6NGjWrNmjWbPnq0pU6ZE5RcAADiXkwPc1jlwl8t10e07duzQsmXL1NzcrB/96Ec6duyYurq6lJGRofvuu0/r1q3r97mFC+c1AABmG4xz4D/4wQ8GfA78T3/605V/DvxyWZ+RkaHq6uoBFQQAgB0md9EDwc1MAADGGmh4mxz+3MwEAAAD0YEDAIzl5A6cAAcAGMvJAc4SOgAABqIDBwAYy8kdOAEOADCWkwOcJXQAAAxEBw4AMJaTO3ACHABgLAIcAAADOTnAOQcOAICB6MABAMZycgdOgAMAjOXkAGcJHQAAA9GBAwCM5eQOnAAHABjLyQHOEjoAAAaiAwcAGMvJHTgBDgAwlpMDnCV0AAAMRAcOADAWHTgAAAayLGvAIxxbt27VX/7lX2r48OHKzs7Wb3/72wj/ZpdHgAMAjBWLAH/rrbdUUlKiDRs26NNPP9XUqVOVl5enU6dOReE3vDQCHAAAG55//nmtWLFCjzzyiCZOnKjt27drxIgRevXVVwe1jiEX4CafjwAA/J/B+vc8Et13Z2dnyOju7r7osXp6enT48GHl5uYGt8XFxSk3N1c1NTVR/12/acgF+OnTp2NdAgAgAqL573lCQoL8fn9EnmvkyJHKyMiQ1+sNjrKysovu+8UXX+jcuXNKTU0N2Z6amqpAIBCRevpryF2Fnp6erubmZiUlJcnlcoU81tnZqYyMDDU3N8vj8cSowtjjdTiP1+E8XofzeB3OGwqvg2VZOn36tNLT06N2jOHDh6uxsVE9PT0Dfi7Lsr6TN263e8DPG21DLsDj4uJ0zTXXfO8+Ho/H0X9BL+B1OI/X4Txeh/N4Hc6L9evg9Xqjfozhw4dr+PDhUT/ON40ePVrx8fFqbW0N2d7a2hqxFYH+GnJL6AAADFUJCQmaPn26qqqqgtv6+vpUVVWlnJycQa1lyHXgAAAMZSUlJVq6dKluueUWzZw5Uy+++KK6urr0yCOPDGodRgW42+3Whg0bjDg3EU28DufxOpzH63Aer8N5vA7R98ADD+iPf/yj1q9fr0AgoGnTpqmiouI7F7ZFm8vic1sAABiHc+AAABiIAAcAwEAEOAAABiLAAQAwkDEBPhRu3RZrGzdulMvlChkTJkyIdVlRd/DgQS1YsEDp6elyuVzas2dPyOOWZWn9+vVKS0tTYmKicnNzdfz48dgUG0WXex2WLVv2nfdHfn5+bIqNkrKyMs2YMUNJSUlKSUnRwoULVVdXF7LP2bNnVVRUpFGjRmnkyJEqLCz8zpdumK4/r8OcOXO+83549NFHY1QxosGIAB8qt24bCm666Sa1tLQEx4cffhjrkqKuq6tLU6dO1datWy/6+ObNm/XSSy9p+/btOnTokK6++mrl5eXp7Nmzg1xpdF3udZCk/Pz8kPfHG2+8MYgVRl91dbWKiopUW1uryspK9fb2at68eerq6grus2bNGr377rt65513VF1drZMnT+r++++PYdWR15/XQZJWrFgR8n7YvHlzjCpGVFgGmDlzplVUVBT8+dy5c1Z6erpVVlYWw6oG34YNG6ypU6fGuoyYkmTt3r07+HNfX5/l9/utn//858Ft7e3tltvttt54440YVDg4vv06WJZlLV261Lr33ntjUk+snDp1ypJkVVdXW5Z1/r/9sGHDrHfeeSe4z+eff25JsmpqamJVZtR9+3WwLMu64447rMcffzx2RSHqhnwHPpRu3TYUHD9+XOnp6Ro3bpyWLFmipqamWJcUU42NjQoEAiHvD6/Xq+zsbEe+Pw4cOKCUlBTdcMMNWrVqldra2mJdUlR1dHRIknw+nyTp8OHD6u3tDXk/TJgwQZmZmVf0++Hbr8MFu3bt0ujRozVp0iSVlpbqq6++ikV5iJIh/01s33frtv/5n/+JUVWxkZ2drZ07d+qGG25QS0uLnnnmGd1+++06duyYkpKSYl1eTFy4fd9QuLVfrOXn5+v+++9XVlaWGhoa9Ld/+7cqKChQTU2N4uPjY11exPX19Wn16tW69dZbNWnSJEnn3w8JCQlKTk4O2fdKfj9c7HWQpAcffFBjx45Venq6jh49qqeeekp1dXX65S9/GcNqEUlDPsDxfwoKCoJ/njJlirKzszV27Fi9/fbbWr58eQwrw1CwaNGi4J8nT56sKVOmaPz48Tpw4IDmzp0bw8qio6ioSMeOHXPEdSDf51Kvw8qVK4N/njx5stLS0jR37lw1NDRo/Pjxg10momDIL6EPpVu3DTXJycm6/vrrVV9fH+tSYubCe4D3x3eNGzdOo0ePviLfH8XFxdq3b58++OCDkNsP+/1+9fT0qL29PWT/K/X9cKnX4WKys7Ml6Yp8PzjVkA/woXTrtqHmzJkzamhoUFpaWqxLiZmsrCz5/f6Q90dnZ6cOHTrk+PfHiRMn1NbWdkW9PyzLUnFxsXbv3q39+/crKysr5PHp06dr2LBhIe+Huro6NTU1XVHvh8u9Dhdz5MgRSbqi3g9OZ8QS+lC5dVusPfHEE1qwYIHGjh2rkydPasOGDYqPj9fixYtjXVpUnTlzJqRraGxs1JEjR+Tz+ZSZmanVq1fr2Wef1XXXXaesrCw9/fTTSk9P18KFC2NXdBR83+vg8/n0zDPPqLCwUH6/Xw0NDXryySd17bXXKi8vL4ZVR1ZRUZHKy8u1d+9eJSUlBc9re71eJSYmyuv1avny5SopKZHP55PH49Fjjz2mnJwczZo1K8bVR87lXoeGhgaVl5dr/vz5GjVqlI4ePao1a9Zo9uzZmjJlSoyrR8TE+jL4/tqyZYuVmZlpJSQkWDNnzrRqa2tjXdKge+CBB6y0tDQrISHB+ou/+AvrgQcesOrr62NdVtR98MEHlqTvjKVLl1qWdf6jZE8//bSVmppqud1ua+7cuVZdXV1si46C73sdvvrqK2vevHnWmDFjrGHDhlljx461VqxYYQUCgViXHVEX+/0lWTt27Aju8+c//9n68Y9/bP3gBz+wRowYYd13331WS0tL7IqOgsu9Dk1NTdbs2bMtn89nud1u69prr7XWrl1rdXR0xLZwRBS3EwUAwEBD/hw4AAD4LgIcAAADEeAAABiIAAcAwEAEOAAABiLAAQAwEAEOAICBCHAAAAxEgAMAYCACHAAAAxHgAAAYiAAHAMBA/w/+eMm2VALGHQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader 구경\n",
        "\n",
        "# 📚 [Deep Dive] Optimizer vs DataLoader: 누가 학습 방식을 결정하는가?\n",
        "\n",
        "\"GD, SGD, Mini-batch GD... 이름은 Optimizer가 가지고 있는데, 왜 결정권은 DataLoader에게 있을까?\"\n",
        "\n",
        "## 1. 핵심 요약: 역할의 분리\n",
        "\n",
        "AI 학습 코드를 짤 때, 이 두 가지 역할을 명확히 구분해야 헷갈리지 않습니다.\n",
        "\n",
        "| 구분 | 코드 (변수명) | 역할 비유 | 실제 하는 일 |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Optimizer** | `optim.SGD` | **요리사 (Chef)** 👨‍🍳 | 재료가 오면 레시피(미분 공식)대로 **요리(업데이트)**만 함. |\n",
        "| **DataLoader** | `DataLoader` | **재료 손질 담당 (Prep)** 🔪 | 창고(Dataset)에서 재료를 꺼내 **몇 개씩 묶어서(Batch)** 줄지 결정함. |\n",
        "\n",
        "> **💡 결론:** 요리사(`optim.SGD`)는 재료가 1개 오든 100개 오든 상관하지 않습니다. **\"한 번에 몇 개를 줄지\"를 정하는 `DataLoader`의 `batch_size`가 학습 방식(SGD vs Mini-batch)을 결정합니다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Batch Size에 따른 학습 방식의 변화\n",
        "\n",
        "`optimizer = optim.SGD(...)` 코드는 그대로 두고, `DataLoader`의 설정만 바꿨을 때 내부 동작이 어떻게 변하는지 확인해 봅시다.\n",
        "\n",
        "### ① Stochastic Gradient Descent (SGD)\n",
        "**\"데이터 1개 보고 1번 수정\"**\n",
        "* **특징:** 가장 기초적인 의미의 SGD.\n",
        "* **설정:** `batch_size=1`\n",
        "* **단점:** 너무 오래 걸리고, 데이터 하나하나의 노이즈(튀는 값)에 휘둘려 학습이 불안정함.\n",
        "\n",
        "```python\n",
        "# 요리사에게 재료를 1개씩 줌\n",
        "train_DL = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "```\n",
        "\n",
        "### ② Batch Gradient Descent (GD)\n",
        "**\"데이터 6만 개(전체) 다 보고 1번 수정\"**\n",
        "* **특징:** 이론적으로 가장 완벽한 방향으로 학습함.\n",
        "* **설정:** `batch_size=len(dataset)`\n",
        "* **단점:** 메모리(RAM)가 터짐. 한 발자국 떼는 데 시간이 너무 오래 걸림.\n",
        "\n",
        "```python\n",
        "# 요리사에게 재료 6만 개를 한 번에 던짐 (주방 마비됨)\n",
        "train_DL = DataLoader(dataset, batch_size=60000, shuffle=True)\n",
        "```\n",
        "\n",
        "### ③ Mini-batch Gradient Descent (★국룰)\n",
        "**\"데이터 32개(적당량) 보고 평균 내서 1번 수정\"**\n",
        "* **특징:** 속도와 안정성의 황금 밸런스. 현업에서 말하는 SGD는 사실 이걸 의미함.\n",
        "* **설정:** `batch_size=32` (또는 64, 128...)\n",
        "* **장점:** GPU 병렬 연산 효율이 좋고, 적당한 노이즈가 있어 과적합도 방지됨.\n",
        "\n",
        "```python\n",
        "# 요리사에게 재료를 32개씩 쟁반에 담아서 줌 (가장 효율적)\n",
        "train_DL = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 코드 흐름으로 완벽 이해하기\n",
        "\n",
        "```python\n",
        "# 1. 수리공 고용 (이름은 SGD지만, 그냥 '업데이트 도구'일 뿐)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 2. 작업 반장(DataLoader)에게 \"32개씩 묶어오라\"고 지시 (여기가 핵심!)\n",
        "# -> 이 숫자가 바로 학습 방식을 결정함\n",
        "BATCH_SIZE = 32\n",
        "train_DL = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# 3. 실전 학습\n",
        "for ep in range(EPOCH):\n",
        "    # loader가 32개씩 포장된 'x_batch'를 던져줌\n",
        "    for x_batch, y_batch in train_DL:\n",
        "        \n",
        "        # [Inference] 32개 문제 동시에 풀기\n",
        "        y_hat = model(x_batch)\n",
        "        \n",
        "        # [Loss] 32개 채점 결과의 '평균' 오차 계산\n",
        "        loss = criterion(y_hat, y_batch)\n",
        "        \n",
        "        # [Update] 평균 오차를 기준으로 가중치 수정\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. 요약 (Takeaway)\n",
        "\n",
        "1. **이름에 속지 말자:** `optim.SGD`를 쓴다고 무조건 1개씩 학습하는 게 아니다.\n",
        "2. **범인은 DataLoader:** 데이터를 몇 묶음으로 쪼개서 줄지(`batch_size`)가 실제 학습의 성격(Mini-batch 여부)을 결정한다.\n",
        "3. **국룰 세팅:** * `optimizer`: Adam 또는 SGD\n",
        "   * `DataLoader`: `batch_size=32` (메모리 상황에 따라 64, 128로 증량)\n",
        "   * `shuffle=True`: 학습 데이터는 무조건 섞어서 줄 것!"
      ],
      "metadata": {
        "id": "aMabJYO-YSIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "aY5QvGbdYVqe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_DL.dataset  # DataLoader는 dataset도 가지고 있다.\n",
        "# DataLoader가 있으면 Dasaset도 같이 있는 셈."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz3KdqB8ZiJP",
        "outputId": "add844fa-57fb-455e-93be-58a6a9ac3a70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /content/drive/MyDrive/ROKAF/인스톨 파이토치/data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ `transforms.ToTensor()`의 3가지 핵심 역할 완벽 해부\n",
        "\n",
        "PyTorch 데이터 전처리에서 가장 먼저 등장하는 `ToTensor()`는 단순히 형식을 바꾸는 것이 아니라, **모델 학습을 위한 최적의 상태**로 데이터를 변환하는 3가지 중요한 작업을 수행합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Data Type 변환: `numpy/PIL` $\\to$ `Tensor`\n",
        "**\"민간인(CPU)을 군인(GPU)으로 입대시키는 과정\"**\n",
        "\n",
        "* **입력:** `PIL Image` 또는 `numpy.ndarray` (CPU 기반)\n",
        "* **출력:** `torch.FloatTensor` (GPU 탑승 가능)\n",
        "* **왜 하는가?**\n",
        "    1.  **GPU 가속:** 오직 Tensor 형태여야만 `.to('cuda')`를 통해 GPU에서 고속 연산이 가능합니다.\n",
        "    2.  **Autograd (자동 미분):** Tensor가 되어야만 역전파(`backward`) 시 미분 계산 경로(`grad_fn`)를 추적할 수 있습니다.\n",
        "    3.  **고속 연산:** 파이토치는 Tensor 형태의 행렬 연산에 극도로 최적화되어 있습니다.\n",
        "\n",
        "## 2. Shape 변경: `(H, W, C)` $\\to$ `(C, H, W)`\n",
        "**\"기계가 좋아하는 순서로 재료 손질 (차원 생성 및 이동)\"**\n",
        "\n",
        "이미지의 종류(흑백/컬러)에 따라 동작 방식이 조금 다릅니다. 핵심은 **\"무조건 채널(Channel)을 맨 앞으로 보낸다\"**는 것입니다.\n",
        "\n",
        "### ① Case A: 흑백 이미지 (예: MNIST)\n",
        "**\"없던 채널(두께)을 만들어준다 (Unsqueeze)\"**\n",
        "* **상황:** 원본 이미지가 채널 정보 없이 `(세로, 가로)` 형태의 2차원 평면일 때.\n",
        "* **동작:** 맨 앞에 차원을 하나 추가해서 3차원으로 만듭니다.\n",
        "* **변환:** `(28, 28)` $\\to$ **`(1, 28, 28)`**\n",
        "    * `1`: 채널 수 (흑백이므로 1)\n",
        "    * `28`: 세로 (Height)\n",
        "    * `28`: 가로 (Width)\n",
        "* **이유:** PyTorch의 합성곱 계층(`nn.Conv2d`)은 입력으로 무조건 `(N, C, H, W)` 형태를 요구하기 때문에, 1장일 때도 반드시 `(C, H, W)` 형태를 갖춰야 합니다.\n",
        "\n",
        "### ② Case B: 컬러 이미지 (예: CIFAR-10, 일반 사진)\n",
        "**\"채널의 위치를 맨 앞으로 이사시킨다 (Permute)\"**\n",
        "* **상황:** 원본 이미지가 `(세로, 가로, 채널)` 순서로 되어 있을 때.\n",
        "* **동작:** 맨 뒤에 있던 채널 축을 맨 앞으로 옮깁니다.\n",
        "* **변환:** `(28, 28, 3)` $\\to$ **`(3, 28, 28)`**\n",
        "    * `3`: 채널 수 (R, G, B)\n",
        "* **이유:** GPU가 메모리를 읽을 때 색깔별로 묶여 있어야(Planar) 연산 속도가 훨씬 빠르기 때문입니다.\n",
        "\n",
        "## 3. Scaling (정규화): `0 ~ 255` $\\to$ `0.0 ~ 1.0`\n",
        "**\"학습 속도와 안정성을 위한 다이어트\"**\n",
        "\n",
        "* **동작:** 입력된 픽셀값(Int)을 255로 나누어 `0.0`에서 `1.0` 사이의 실수(Float)로 변환합니다.\n",
        "* **왜 하는가?**\n",
        "    1.  **학습 속도 향상:** 입력값이 작아야 오차 곡선이 완만해져서 최적점(Loss=0)으로 빠르게 직진할 수 있습니다. (큰 값은 지그재그로 학습됨)\n",
        "    2.  **기울기 소실(Vanishing Gradient) 방지:** 값이 너무 크면 활성화 함수(Sigmoid 등)의 기울기가 0이 되어 학습이 멈추는 현상을 막습니다.\n",
        "    3.  **계산 정밀도:** 컴퓨터가 실수를 계산할 때 가장 오차가 적은 범위입니다.\n",
        "\n",
        "---\n",
        "\n",
        "### ⚡ 요약: Before & After\n",
        "\n",
        "| 구분 | 전 (Raw Data) | 후 (ToTensor 적용) | 비고 |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **자료형** | `numpy.uint8` (정수) | `torch.float32` (실수) | GPU 연산 최적화 |\n",
        "| **값의 범위** | `0` ~ `255` | `0.0` ~ `1.0` | 학습 안정성 확보 |\n",
        "| **흑백 차원** | `(H, W)` | **`(1, H, W)`** | **채널 차원 생성** |\n",
        "| **컬러 차원** | `(H, W, C)` | **`(C, H, W)`** | **채널 축 이동** |"
      ],
      "metadata": {
        "id": "N6aRIWrplrTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_DL)) # 데이터 한 국자 # next(iter(train_DS)) 는 한 장만 꺼내기\n",
        "\n",
        "# ToTensor 의 역할\n",
        "# 1. tensor로 바꾸고\n",
        "# 2. \"개 채 행 열\" 로 바꾸고  (흑백이면 채=1, 컬러면 채=3)\n",
        "#    여기선 \"60000 X 1 X 28 X 28\"\n",
        "# 3. 0~255 값을 0~1 사이로 바꾼다. (int -> float)\n",
        "\n",
        "print(\"======DS=======\")\n",
        "print(type(train_DS.data))\n",
        "print(train_DS.data.shape)  # 개 행 열\n",
        "print(train_DS.data.dtype)\n",
        "print(train_DS.data[0])\n",
        "print(\"======ToTensor 후======\")\n",
        "print(type(x_batch))\n",
        "print(x_batch.shape)  # 개 채 행 열\n",
        "print(x_batch.dtype)\n",
        "print(x_batch[0])\n",
        "\n",
        "plt.imshow(x_batch[0].squeeze(),cmap='gray')\n",
        "plt.colorbar()\n",
        "print(y_batch[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nx2Xoc1lZsTu",
        "outputId": "9e631c7a-b8dc-49a0-d255-d0a9c4a80323"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======DS=======\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([60000, 28, 28])\n",
            "torch.uint8\n",
            "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
            "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
            "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
            "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
            "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
            "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
            "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
            "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
            "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
            "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
            "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
            "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
            "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
            "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
            "       dtype=torch.uint8)\n",
            "======ToTensor 후======\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([32, 1, 28, 28])\n",
            "torch.float32\n",
            "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.2745, 0.9922, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.5569, 0.9882, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1333,\n",
            "          0.9176, 0.9882, 0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
            "          0.9882, 0.9882, 0.6157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
            "          0.9882, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.6667,\n",
            "          0.9922, 0.9922, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9882,\n",
            "          0.9882, 0.9216, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882,\n",
            "          0.9882, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9137, 0.9882,\n",
            "          0.9882, 0.1765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 0.9922, 0.9882,\n",
            "          0.7412, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.9137, 1.0000, 0.8941,\n",
            "          0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.6510, 0.9882, 0.9922, 0.7255,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.2000, 0.9412, 0.9882, 0.9922, 0.3608,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4392, 0.9882, 0.9882, 0.7529, 0.0667,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0863, 0.8431, 0.9882, 0.9882, 0.2471, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.4314, 0.9922, 0.9922, 0.7451, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0196, 0.6980, 0.9882, 0.9882, 0.2510, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.2157, 0.9882, 0.9882, 0.8902, 0.0627, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9137, 0.9882, 0.9882, 0.4667, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.7882, 0.9882, 0.7412, 0.0157, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]])\n",
            "tensor(1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 본격적으로 model 만들기!"
      ],
      "metadata": {
        "id": "QeXGgA_nmNCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "NjrRb05uewMp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fcs=nn.Sequential(\n",
        "            nn.Linear(1*28*28, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10),\n",
        "            # 여기에 softmax 안 넣는게 맞다!!!\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x,start_dim=1)  # 1dim 부터 끝까지 합쳐라\n",
        "        x = self.fcs(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zIIUjPooaQlC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 nn.Linear의 입력 구조와 Flatten의 진정한 의미 (Feature 관점): ⭐⭐⭐⭐⭐\n",
        "\n",
        "`nn.Linear`를 이해할 때는 \"이미지를 편다\"는 행위보다, **\"Feature(특징) 차원을 어떻게 정의할 것인가\"**가 핵심입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. `nn.Linear`의 입력 규칙: `... X 채(Feature)`\n",
        "`nn.Linear`는 입력 텐서의 **맨 마지막 차원**을 **'특징(Feature) 채널'**로 인식합니다. 앞쪽 차원(Batch 등)이 몇 개가 있든 상관없이, 마지막 차원만 맞으면 작동합니다.\n",
        "\n",
        "* **입력 가능 형태:**\n",
        "    * `(채)` $\\to$ 데이터 1개\n",
        "    * `(개, 채)` $\\to$ 데이터 N개 묶음 (Batch)\n",
        "    * `(개, 개, 채)` $\\to$ 데이터 N개 조의 묶음\n",
        "    * `(개, ..., 채)`\n",
        "\n",
        "> **핵심 정의:** 여기서 **'채(Channel)'**는 단순히 색상(Color)을 뜻하는 게 아니라, **\"하나의 데이터를 설명하는 모든 특징(in_features)의 개수\"**를 뜻합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 이미지 데이터(MNIST)에서의 '채(Feature)' 정의\n",
        "\n",
        "MNIST 원본 데이터는 `(60000, 1, 28, 28)` 형태입니다. 여기서 **60000(개)**을 제외한 나머지 부분이 **하나의 이미지 데이터**입니다.\n",
        "\n",
        "그렇다면 이 이미지의 **진정한 Feature(채)**는 무엇일까요?\n",
        "* `1` (색상 채널)인가? $\\to$ **NO.** (색상 정보만으로는 그림을 설명 불가)\n",
        "* `28` (가로/세로)인가? $\\to$ **NO.**\n",
        "* **`1 × 28 × 28` (전체 픽셀)인가? $\\to$ YES.**\n",
        "\n",
        "즉, 이 데이터는 **784개의 특징(Feature)**을 가진 데이터입니다.\n",
        "따라서 `nn.Linear`에게 전달해야 할 **'채(Feature)'의 크기는 784**가 됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Flatten의 역할: `개 X 채` 형태로 맞추기\n",
        "\n",
        "우리의 목표는 `(60000, 1, 28, 28)`을 `nn.Linear`가 좋아하는 **`(개, 채)`** 형태로 만드는 것입니다.\n",
        "\n",
        "* **현재 상태:** `(개, color, 행, 열)`\n",
        "    * 여기서 `color, 행, 열`이 흩어져 있음.\n",
        "* **목표 상태:** `(개, Feature)`\n",
        "    * 여기서 `Feature` = `color × 행 × 열`\n",
        "\n",
        "따라서 **`start_dim=1`**을 사용하여, 1번 차원부터 끝까지를 **하나의 'Feature 차원(채)'**으로 통합(Flatten)하는 것입니다.\n",
        "\n",
        "$$\n",
        "\\text{Shape: } (60000, \\underbrace{1, 28, 28}_{\\text{흩어진 특징들}}) \\xrightarrow{\\text{Flatten(start\\_dim=1)}} (60000, \\underbrace{784}_{\\text{통합된 채(Feature)}})\n",
        "$$\n",
        "\n",
        "## ⚡ 결론\n",
        "1. **Linear의 관점:** 입력은 반드시 `(..., Feature)` 형태여야 한다.\n",
        "2. **이미지의 Feature:** 픽셀 하나하나가 모두 특징이므로, `채널 × 세로 × 가로` 전체가 **하나의 거대한 Feature(채)**가 된다.\n",
        "3. **Flatten의 이유:** 흩어져 있는 차원들(`1, 28, 28`)을 `nn.Linear`가 인식할 수 있는 **하나의 Feature 차원(`784`)**으로 합쳐주기 위함이다."
      ],
      "metadata": {
        "id": "1iMIO7zy0XIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten 확인\n",
        "x_batch, _ = next(iter(train_DL))\n",
        "print(x_batch.shape)\n",
        "flat_images = torch.flatten(x_batch)\n",
        "print(flat_images.shape)\n",
        "flat_images2 = torch.flatten(x_batch, start_dim=1)\n",
        "print(flat_images2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9M1T7kV0XgD",
        "outputId": "955a0b8d-13d0-4bb7-dc79-0fdd47dbd6b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([25088])\n",
            "torch.Size([32, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 핵심 포인트: Device Matching\n",
        "파이토치에서는 **연산하려는 두 텐서(모델의 가중치 W와 입력 데이터 X)가 물리적으로 같은 메모리 공간**에 있어야 합니다.\n",
        "* `model.to(DEVICE)` (O)\n",
        "* `data.to(DEVICE)` (O)\n",
        "* 둘 중 하나라도 빠지면 `RuntimeError` 발생."
      ],
      "metadata": {
        "id": "FshTawhYX7zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스 생성 후 cuda로 보내기\n",
        "model=MLP().to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# 시험 삼아 넣어보기\n",
        "x_batch, _= next(iter(train_DL))\n",
        "print(model(x_batch.to(DEVICE)).shape) # 모든 텐서는 같은 gpu 위에 있어야 함.\n",
        "\n",
        "# 결과로 10개의 logit값이 나온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjGWs7ML1APD",
        "outputId": "aff8de97-ec81-440c-f1ba-df35f53d0ab4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fcs): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련시키기"
      ],
      "metadata": {
        "id": "2DnMOm8Rdlku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "GQKtjtjg1opu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_DL.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR2r7besfLjO",
        "outputId": "12911536-01ae-4b2d-dedd-1d95e197c3b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Quiz] 다중 분류 학습 시 Epoch Loss 계산의 함정\n",
        "\n",
        "마지막 배치의 크기가 다를 때, 정확한 Epoch Loss를 계산하는 방법을 이해했는지 확인하는 문제입니다.\n",
        "\n",
        "## 1. 상황 설정 (Scenario)\n",
        "* **전체 데이터 (`NoT`):** 10개\n",
        "* **배치 크기 (`BATCH_SIZE`):** 4개\n",
        "* **배치별 결과:**\n",
        "  1. **Batch 1 (4개):** 평균 Loss **1.0**\n",
        "  2. **Batch 2 (4개):** 평균 Loss **1.0**\n",
        "  3. **Batch 3 (2개):** 평균 Loss **6.0** (※ 마지막 자투리 배치)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 문제 (Question)\n",
        "**Q. 위 상황에서 이번 Epoch의 최종 Loss(`loss_e`)는 얼마인가?**\n",
        "\n",
        "* **A)** 2.66\n",
        "* **B)** 2.0\n",
        "* **C)** 8.0\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 정답 및 해설 (Solution)\n",
        "\n",
        "### ✅ 정답: B) 2.0\n",
        "\n",
        "### ❌ 오답 분석 (A를 고른 경우: 단순 평균의 함정)\n",
        "배치별 Loss를 단순히 더해서 배치의 수(3번)로 나누면 틀립니다.\n",
        "$$(1.0 + 1.0 + 6.0) \\div 3 = 2.66$$\n",
        "> **이유:** 데이터가 2개뿐인 마지막 배치가, 데이터가 4개인 앞선 배치들과 동등한 비중(1/3)을 차지하게 되어 평균이 왜곡됩니다.\n",
        "\n",
        "### ⭕ 정답 분석 (B: 가중 평균)\n",
        "우리가 작성한 코드는 **데이터 개수(Weight)**를 곱해서 총합을 구한 뒤, 전체 개수로 나눕니다.\n",
        "\n",
        "**1. 코드 로직 복기**\n",
        "```python\n",
        "loss_b = loss.item() * x_batch.shape[0] # 평균 × 개수 = 총합\n",
        "rloss += loss_b\n",
        "```\n",
        "\n",
        "**2. 실제 계산 과정**\n",
        "* **Batch 1:** $1.0 \\times 4 = 4.0$\n",
        "* **Batch 2:** $1.0 \\times 4 = 4.0$\n",
        "* **Batch 3:** $6.0 \\times 2 = 12.0$ (※ 여기서 4를 곱하면 안 됨!)\n",
        "* **Total Sum:** $4.0 + 4.0 + 12.0 = 20.0$\n",
        "\n",
        "**3. 최종 Epoch Loss**\n",
        "$$\\text{Epoch Loss} = \\frac{\\text{Total Sum}}{\\text{Total Data}} = \\frac{20.0}{10} = \\mathbf{2.0}$$\n",
        "\n",
        "## 4. 핵심 요약 (Key Takeaway)\n",
        "* **`x_batch.shape[0]`를 쓰는 이유:** 마지막 배치는 설정한 `BATCH_SIZE`보다 작을 수 있습니다. 이때 실제 데이터 개수를 반영해야 정확한 전체 평균을 구할 수 있습니다."
      ],
      "metadata": {
        "id": "voWiz5Wg49y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR=1e-3\n",
        "EPOCH=5\n",
        "criterion=nn.CrossEntropyLoss() # softmax 여기에 내장되어있음!!!\n",
        "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "def Train(model, train_DL, criterion, optimizer, EPOCH):\n",
        "\n",
        "    loss_history=[]\n",
        "    NoT=len(train_DL.dataset) # The number of training data\n",
        "\n",
        "    model.train() # train 모드 전환\n",
        "    for ep in range(EPOCH):\n",
        "        rloss=0 # running loss : 현재 Epoch 내에서 발생한 모든 데이터의 오차 총합\n",
        "        for x_batch, y_batch in train_DL:\n",
        "            x_batch=x_batch.to(DEVICE)\n",
        "            y_batch=y_batch.to(DEVICE)\n",
        "\n",
        "            # inference\n",
        "            y_hat = model(x_batch)\n",
        "            # loss\n",
        "            loss = criterion(y_hat,y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # backward\n",
        "            loss.backward()\n",
        "            # update\n",
        "            optimizer.step()\n",
        "\n",
        "            # loss accumulation => 32개씩 받아오는데 마지막 몇개는 32개가 아닐 수 있음.\n",
        "            loss_b = loss.item() * x_batch.shape[0] # batch loss  # BATCH_SIZE를 곱하면 안 됨 : 마지막 몇개 32개가 아닐 수 있으니까.\n",
        "            rloss += loss_b\n",
        "        # print loss\n",
        "        loss_e = rloss/NoT # epoch loss\n",
        "        loss_history += [loss_e]\n",
        "        print(f\"Epoch: {ep+1}, trian loss: {loss_e:.3f}\")\n",
        "        print('='*20)\n",
        "    return loss_history\n"
      ],
      "metadata": {
        "id": "rIKbeOnZeh0_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [PyTorch] Loss 계산의 정석: Batch vs Epoch Loss\n",
        "\n",
        "## 1. 용어 정리\n",
        "* **Batch Loss (`loss` 변수):** `Batch Size`(예: 32개)만큼의 데이터에 대한 **평균** 오차. (`CrossEntropyLoss`의 기본 동작)\n",
        "* **Running Loss (`rloss` 변수):** 현재 Epoch 내에서 발생한 **모든 데이터의 오차 총합**.\n",
        "* **Epoch Loss (`loss_e` 변수):** 전체 데이터(`NoT`)에 대한 정확한 **평균** 오차.\n",
        "\n",
        "## 2. 코드 로직 분석 (Why?)\n",
        "\n",
        "```python\n",
        "# 1. loss는 '평균'입니다. (예: 32개 데이터의 평균 점수)\n",
        "loss = criterion(y_hat, y_batch)\n",
        "\n",
        "# 2. 전체 합을 구하기 위해 다시 개수를 곱해줍니다.\n",
        "# x_batch.shape[0]를 쓰는 이유:\n",
        "# 마지막 배치는 32개가 아니라 10개, 5개 등 '자투리'일 수 있기 때문입니다.\n",
        "# BATCH_SIZE 상수를 곱하면 마지막 배치에서 오차가 뻥튀기 됩니다.\n",
        "loss_b = loss.item() * x_batch.shape[0]\n",
        "\n",
        "# 3. 바구니에 담습니다.\n",
        "rloss += loss_b\n",
        "\n",
        "# 4. Epoch이 끝나면 전체 데이터 개수로 나눕니다.\n",
        "# 이것이 진정한 '전체 데이터에 대한 평균 Loss'입니다.\n",
        "loss_e = rloss / NoT\n",
        "```\n",
        "\n",
        "## 3. 핵심 포인트\n",
        "* **`loss.item()`**: 텐서에서 숫자(Scalar) 값만 쏙 빼내는 함수 (메모리 절약).\n",
        "* **`x_batch.shape[0]`**: 현재 배치의 **실제 크기**. (항상 `BATCH_SIZE`와 같지 않음에 주의!)\n",
        "* **가중 평균의 원리**: 배치마다 데이터 개수가 다를 수 있으므로, 단순 평균이 아닌 개수를 고려한 합산을 해야 한다."
      ],
      "metadata": {
        "id": "3LS28Akw0iqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train(model, train_DL, criterion, optimizer, EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWgeo-oI1BjF",
        "outputId": "b712bece-873b-4c3c-bc1e-0b2f966b59cc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, trian loss: 0.047\n",
            "====================\n",
            "Epoch: 2, trian loss: 0.037\n",
            "====================\n",
            "Epoch: 3, trian loss: 0.030\n",
            "====================\n",
            "Epoch: 4, trian loss: 0.024\n",
            "====================\n",
            "Epoch: 5, trian loss: 0.021\n",
            "====================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04731744677958389,\n",
              " 0.037434731106041,\n",
              " 0.030359824111902467,\n",
              " 0.024369238310997996,\n",
              " 0.021055890945442177]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}